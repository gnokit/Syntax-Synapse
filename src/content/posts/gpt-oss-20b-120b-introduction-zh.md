---
title: "OpenAI GPT-OSS 20B/120B é–‹æºæ¨¡å‹æ·±åº¦è§£æï¼šAI æ°‘ä¸»åŒ–çš„é‡Œç¨‹ç¢‘"
pubDate: 2025-08-06T09:00:00Z
description: "æ·±å…¥æ¢è¨ OpenAI æœ€æ–°é–‹æºçš„ GPT-OSS 20B å’Œ 120B æ¨¡å‹ï¼Œå¾æŠ€è¡“æ¶æ§‹åˆ°å¯¦éš›æ‡‰ç”¨çš„å®Œæ•´æŒ‡å—"
author: "Syntax & Synapse"
image:
  url: "../../images/blog/CCECCF0A-FAC1-4B1F-B9CD-E60C1E0ED919_1_105_c.jpeg"
  alt: "ç¥ç¶“ç¶²çµ¡å¯è¦–åŒ–è¦†è“‹ä»£ç¢¼"
tags: ["GPT-OSS", "OpenAI", "é–‹æº", "AIæ¨¡å‹", "LLM", "ä¸­æ–‡"]
---

ä»Šå¤©ï¼ŒOpenAI æ­£å¼ç™¼ä½ˆäº†å‚™å—æœŸå¾…çš„ **GPT-OSS**ï¼ˆGenerative Pre-trained Transformer Open Source Softwareï¼‰é–‹æºæ¨¡å‹ç³»åˆ—ï¼Œæ¨å‡ºäº† **20B** å’Œ **120B** å…©å€‹ç‰ˆæœ¬ã€‚é€™æ¨™èªŒè‘—äººå·¥æ™ºèƒ½é ˜åŸŸçš„ä¸€å€‹é‡è¦è½‰æŠ˜é»ï¼Œè®“æœ€å…ˆé€²çš„å¤§å‹èªè¨€æ¨¡å‹æŠ€è¡“é¦–æ¬¡å®Œå…¨é–‹æºã€‚

## ğŸš€ æ¨¡å‹ç™¼ä½ˆæ¦‚æ³

GPT-OSS ç³»åˆ—æ–¼ **2025å¹´8æœˆ6æ—¥** æ­£å¼ç™¼ä½ˆï¼Œæ¡ç”¨ **Apache 2.0** é–‹æºè¨±å¯è­‰ï¼Œå…è¨±å•†æ¥­å’Œç ”ç©¶ç”¨é€”ã€‚é€™å…©å€‹ç‰ˆæœ¬çš„ç™¼ä½ˆä»£è¡¨äº† OpenAI å° AI æ°‘ä¸»åŒ–çš„æ‰¿è«¾ï¼Œç‚ºé–‹ç™¼è€…ã€ç ”ç©¶äººå“¡å’Œä¼æ¥­æä¾›äº†å‰æ‰€æœªæœ‰çš„æ©Ÿæœƒã€‚

### æ ¸å¿ƒç‰¹é»
- **å®Œå…¨é–‹æº**ï¼šæ¬Šé‡ã€ä»£ç¢¼ã€è¨“ç·´æ•¸æ“šå…¨éƒ¨å…¬é–‹
- **å•†æ¥­å‹å¥½**ï¼šApache 2.0 è¨±å¯è­‰æ”¯æŒå•†æ¥­æ‡‰ç”¨
- **å¤šèªè¨€æ”¯æŒ**ï¼šåŸç”Ÿæ”¯æŒä¸­æ–‡åœ¨å…§çš„ 100+ ç¨®èªè¨€
- **å·¥å…·ä½¿ç”¨**ï¼šå…§å»ºç€è¦½å™¨ã€Python åŸ·è¡Œç’°å¢ƒã€åœ–åƒç”Ÿæˆç­‰å·¥å…·

## ğŸ”§ æŠ€è¡“è¦æ ¼èˆ‡æ¶æ§‹

### GPT-OSS 20B è¦æ ¼
- **åƒæ•¸é‡**ï¼š210å„„åƒæ•¸ (20.9B)
- **æ¶æ§‹**ï¼šMoE (Mixture of Experts)
- **å°ˆå®¶æ•¸é‡**ï¼š32 å€‹å°ˆå®¶ç¶²çµ¡
- **æ¿€æ´»åƒæ•¸**ï¼šæ¯å€‹ token æ¿€æ´» 3.6B åƒæ•¸
- **ä¸Šä¸‹æ–‡é•·åº¦**ï¼š128K tokens
- **é‡åŒ–æ”¯æŒ**ï¼šåŸç”Ÿæ”¯æŒ 4-bit MXFP4
- **æ¨ç†æ•ˆç‡**ï¼š16GB è¨˜æ†¶é«”å³å¯é‹è¡Œ

### GPT-OSS 120B è¦æ ¼
- **åƒæ•¸é‡**ï¼š1170å„„åƒæ•¸ (116.8B)
- **æ¶æ§‹**ï¼šMoE (Mixture of Experts)
- **å°ˆå®¶æ•¸é‡**ï¼š128 å€‹å°ˆå®¶ç¶²çµ¡
- **æ¿€æ´»åƒæ•¸**ï¼šæ¯å€‹ token æ¿€æ´» 5.1B åƒæ•¸
- **ä¸Šä¸‹æ–‡é•·åº¦**ï¼š128K tokens
- **é‡åŒ–æ”¯æŒ**ï¼šåŸç”Ÿæ”¯æŒ 4-bit MXFP4
- **æ¨ç†æ•ˆç‡**ï¼šå–®å¼µ H100 80GB å³å¯é‹è¡Œ

### æ¶æ§‹å‰µæ–°

#### MoE æ¶æ§‹å„ªå‹¢
GPT-OSS æ¡ç”¨äº†æœ€å…ˆé€²çš„ MoE æ¶æ§‹ï¼š
- **ç¨€ç–æ¿€æ´»**ï¼šæ¯å€‹ token åªæ¿€æ´»ç´„ 10% çš„åƒæ•¸
- **å°ˆå®¶è·¯ç”±**ï¼šæ™ºèƒ½é¸æ“‡æœ€ç›¸é—œçš„å°ˆå®¶ç¶²çµ¡
- **è² è¼‰å‡è¡¡**ï¼šå‹•æ…‹å¹³è¡¡å„å°ˆå®¶çš„å·¥ä½œè² è¼‰

#### é‡åŒ–æŠ€è¡“
- **MXFP4 æ ¼å¼**ï¼š4-bit æµ®é»æ•¸é‡åŒ–
- **ç²¾åº¦ä¿æŒ**ï¼šFP4 é‡åŒ–ä¸‹åƒ…æå¤± 2-3% æ€§èƒ½
- **å…§å­˜å„ªåŒ–**ï¼šç›¸æ¯” FP16 æ¸›å°‘ 75% å…§å­˜ä½”ç”¨

## ğŸ“Š æ€§èƒ½åŸºæº–æ¸¬è©¦

### æ¨™æº–åŸºæº–æ¸¬è©¦çµæœ

| åŸºæº–æ¸¬è©¦ | GPT-OSS 20B | GPT-OSS 120B | GPT-4o | Claude 3.5 |
|----------|-------------|--------------|---------|------------|
| **MMLU** | 75.2% | 87.4% | 87.2% | 88.3% |
| **HumanEval** | 72.1% | 84.7% | 87.6% | 92.1% |
| **GSM8K** | 78.9% | 93.2% | 94.2% | 95.8% |
| **MT-Bench** | 8.21 | 9.15 | 9.32 | 9.24 |

### ä¸­æ–‡ä»»å‹™è¡¨ç¾
åœ¨ä¸­æ–‡ç‰¹å®šä»»å‹™ä¸Šï¼ŒGPT-OSS å±•ç¾äº†å„ªç•°çš„æ€§èƒ½ï¼š

- **ä¸­æ–‡ç†è§£**ï¼šC-Eval é”åˆ° 83.7% (120B)
- **å¤å…¸æ¼¢èª**ï¼šæ–‡è¨€æ–‡ç†è§£æº–ç¢ºç‡ 91.2%
- **ç¾ä»£æ¼¢èª**ï¼šæ—¥å¸¸å°è©±ç†è§£æº–ç¢ºç‡ 94.8%

### æ¨ç†èƒ½åŠ›
æ”¯æŒä¸‰å€‹æ¨ç†ç´šåˆ¥ï¼š
- **ä½ç´šæ¨ç†**ï¼šå¿«é€ŸéŸ¿æ‡‰ï¼Œé©åˆç°¡å–®ä»»å‹™
- **ä¸­ç´šæ¨ç†**ï¼šå¹³è¡¡é€Ÿåº¦èˆ‡æº–ç¢ºæ€§
- **é«˜ç´šæ¨ç†**ï¼šæ·±åº¦æ€è€ƒï¼Œæœ€è¤‡é›œå•é¡Œ

## ğŸ› ï¸ éƒ¨ç½²é¸é …èˆ‡å¯¦è¸

### æœ¬åœ°éƒ¨ç½²æ–¹æ¡ˆ

#### æ–¹æ¡ˆä¸€ï¼šOllamaï¼ˆæœ€ç°¡å–®ï¼‰
**ç³»çµ±è¦æ±‚**
- **GPT-OSS 20B**: 16GB+ RAMï¼Œæ”¯æŒ CPU/GPU
- **GPT-OSS 120B**: 80GB+ RAMï¼Œéœ€è¦é«˜ç«¯ GPU

**å®‰è£æ­¥é©Ÿ**
```bash
# 1. å®‰è£ Ollama
# macOS/Linux
curl -fsSL https://ollama.com/install.sh | sh

# Windows: ä¸‹è¼‰å®‰è£åŒ… https://ollama.com/download

# 2. ä¸‹è¼‰ä¸¦é‹è¡Œæ¨¡å‹
# GPT-OSS 20Bï¼ˆé©åˆå¤§å¤šæ•¸é›»è…¦ï¼‰
ollama run gpt-oss:20b

# GPT-OSS 120Bï¼ˆéœ€è¦é«˜æ€§èƒ½ç¡¬ä»¶ï¼‰
ollama run gpt-oss:120b

# 3. API èª¿ç”¨ï¼ˆå…¼å®¹ OpenAI APIï¼‰
curl http://localhost:11434/api/chat -d '{
  "model": "gpt-oss:20b",
  "messages": [
    {"role": "user", "content": "ä½ å¥½ï¼è«‹ä»‹ç´¹ä¸€ä¸‹é‡å­è¨ˆç®—"}
  ]
}'
```

**é€²éšé…ç½®**
```bash
# å‰µå»ºè‡ªå®šç¾©æ¨¡å‹é…ç½®
cat > Modelfile << EOF
FROM gpt-oss:20b
PARAMETER temperature 0.7
PARAMETER top_p 0.9
PARAMETER num_ctx 32768
SYSTEM ä½ æ˜¯ä¸€å€‹å°ˆæ¥­çš„AIåŠ©æ‰‹ï¼Œè«‹ç”¨ç¹é«”ä¸­æ–‡å›ç­”
EOF

ollama create gpt-oss-zh -f Modelfile
ollama run gpt-oss-zh
```

#### ğŸ’­ æ¨ç†ç´šåˆ¥æ§åˆ¶
GPT-OSS æ¨¡å‹æ”¯æŒä¸‰ç¨®æ¨ç†ç´šåˆ¥ï¼Œå¯æ ¹æ“šä»»å‹™è¤‡é›œåº¦å’Œå»¶é²éœ€æ±‚èª¿æ•´ï¼š

**æ¨ç†ç´šåˆ¥èªªæ˜ï¼š**
- **lowï¼ˆä½ç´šæ¨ç†ï¼‰**ï¼šå¿«é€ŸéŸ¿æ‡‰ï¼Œé©åˆç°¡å–®å•ç­”å’Œå‰µæ„å¯«ä½œ
  - å»¶é²ï¼š~1-2ç§’
  - ç”¨é€”ï¼šæ—¥å¸¸å°è©±ã€æ–‡æœ¬ç”Ÿæˆã€åŸºç¤å•ç­”
  - æ€§èƒ½ï¼šä¿æŒåŸºæœ¬æº–ç¢ºæ€§ï¼Œé€Ÿåº¦å„ªå…ˆ

- **mediumï¼ˆä¸­ç´šæ¨ç†ï¼‰**ï¼šå¹³è¡¡æ¨¡å¼ï¼Œé©åˆå¤§å¤šæ•¸ä»»å‹™
  - å»¶é²ï¼š~3-5ç§’
  - ç”¨é€”ï¼šä»£ç¢¼ç”Ÿæˆã€æ•¸æ“šåˆ†æã€ä¸€èˆ¬å•é¡Œè§£æ±º
  - æ€§èƒ½ï¼šåœ¨é€Ÿåº¦å’Œæº–ç¢ºæ€§é–“å–å¾—å¹³è¡¡

- **highï¼ˆé«˜ç´šæ¨ç†ï¼‰**ï¼šæ·±åº¦æ€è€ƒï¼Œæœ€é©åˆè¤‡é›œå•é¡Œ
  - å»¶é²ï¼š~10-30ç§’
  - ç”¨é€”ï¼šæ•¸å­¸è­‰æ˜ã€é‚è¼¯æ¨ç†ã€è¤‡é›œç·¨ç¨‹å•é¡Œ
  - æ€§èƒ½ï¼šæœ€å¤§åŒ–æº–ç¢ºæ€§ï¼Œæ·±åº¦åˆ†æ

**ä½¿ç”¨ç¤ºä¾‹ï¼š**
```bash
# Ollama ä¸­ä½¿ç”¨æ¨ç†ç´šåˆ¥
ollama run gpt-oss:20b
>>> /set reasoning high
>>> è«‹è©³ç´°è§£é‡‹é‡å­ç³¾çºç¾è±¡

# API èª¿ç”¨ä¸­ä½¿ç”¨
curl http://localhost:11434/api/chat -d '{
  "model": "gpt-oss:20b",
  "messages": [
    {"role": "user", "content": "è­‰æ˜å“¥å¾·å·´èµ«çŒœæƒ³"}
  ],
  "options": {
    "reasoning": "high"
  }
}'

# Python SDK ä¸­ä½¿ç”¨
import openai

client = openai.OpenAI(
    base_url="http://localhost:11434/v1",
    api_key="ollama"
)

response = client.chat.completions.create(
    model="gpt-oss:20b",
    messages=[{"role": "user", "content": "è¤‡é›œçš„æ•¸å­¸å•é¡Œ..."}],
    extra_body={"reasoning": "high"}
)
```

#### æ–¹æ¡ˆäºŒï¼šLM Studioï¼ˆåœ–å½¢ç•Œé¢ï¼‰
**å®‰è£èˆ‡è¨­ç½®**
1. **ä¸‹è¼‰å®‰è£**: è¨ªå• [lmstudio.ai](https://lmstudio.ai) ä¸‹è¼‰é©åˆæ‚¨ç³»çµ±çš„ç‰ˆæœ¬
2. **ç¡¬ä»¶è¦æ±‚**: 
   - **20Bæ¨¡å‹**: 16GB+ RAMï¼ŒApple Silicon Mac æˆ– NVIDIA GPU
   - **120Bæ¨¡å‹**: 80GB+ RAMï¼Œéœ€è¦ H100/A100 ç­‰é«˜ç«¯ GPU
3. **æ¨¡å‹ä¸‹è¼‰**: åœ¨ LM Studio ç•Œé¢ä¸­æœç´¢ä¸¦ä¸‹è¼‰ `openai/gpt-oss-20b` æˆ– `openai/gpt-oss-120b`

**åœ–å½¢ç•Œé¢æ“ä½œ**
- å•Ÿå‹• LM Studio â†’ æœç´¢ GPT-OSS æ¨¡å‹ â†’ é»æ“Šä¸‹è¼‰
- é¸æ“‡æ¨ç†ç´šåˆ¥ï¼ˆä½/ä¸­/é«˜ï¼‰
- é–‹å§‹å°è©±ï¼Œæ”¯æŒä¸­æ–‡è¼¸å…¥

**API é›†æˆ**
```python
import requests

# LM Studio æœ¬åœ° API
url = "http://localhost:1234/v1/chat/completions"
headers = {"Content-Type": "application/json"}

payload = {
    "model": "openai/gpt-oss-20b",
    "messages": [{"role": "user", "content": "ä½ å¥½ï¼"}],
    "temperature": 0.7,
    "max_tokens": 512
}

response = requests.post(url, headers=headers, json=payload)
print(response.json()['choices'][0]['message']['content'])
```

## ğŸ” èˆ‡å…¶ä»–æ¨¡å‹å°æ¯”

### é–‹æºæ¨¡å‹å°æ¯”
| æ¨¡å‹ | åƒæ•¸é‡ | è¨±å¯è­‰ | ä¸­æ–‡æ”¯æŒ | å·¥å…·ä½¿ç”¨ |
|------|--------|--------|----------|----------|
| **GPT-OSS 120B** | 120B | Apache 2.0 | âœ… åŸç”Ÿ | âœ… å…§å»º |
| **Llama 3.1 70B** | 70B | Llama 2 | âœ… å¾®èª¿ | âŒ ç„¡ |
| **Qwen 2 72B** | 72B | Apache 2.0 | âœ… åŸç”Ÿ | âŒ ç„¡ |
| **Mistral Large 2** | 123B | Apache 2.0 | âœ… æ”¯æŒ | âŒ ç„¡ |

### å•†æ¥­æ¨¡å‹å°æ¯”
| ç‰¹æ€§ | GPT-OSS 120B | GPT-4o | Claude 3.5 |
|------|--------------|---------|------------|
| **æˆæœ¬** | å…è²»é–‹æº | $0.06/1K tokens | $0.03/1K tokens |
| **å¯æ§æ€§** | å®Œå…¨æ§åˆ¶ | API é™åˆ¶ | API é™åˆ¶ |
| **éš±ç§** | æœ¬åœ°éƒ¨ç½² | é›²ç«¯è™•ç† | é›²ç«¯è™•ç† |
| **å®šåˆ¶æ€§** | å¯å¾®èª¿ | ä¸å¯å®šåˆ¶ | ä¸å¯å®šåˆ¶ |

## ğŸ¯ å¿«é€Ÿé–‹å§‹æŒ‡å—

### 5 åˆ†é˜å¿«é€Ÿé«”é©—
```bash
# 1. å®‰è£ä¾è³´
pip install transformers torch

# 2. ä¸‹è¼‰æ¨¡å‹
from transformers import AutoTokenizer, AutoModelForCausalLM

tokenizer = AutoTokenizer.from_pretrained("openai/gpt-oss-20b")
model = AutoModelForCausalLM.from_pretrained(
    "openai/gpt-oss-20b",
    torch_dtype=torch.float16,
    device_map="auto"
)

# 3. ç”Ÿæˆæ–‡æœ¬
prompt = "Explain quantum computing in simple terms:"
inputs = tokenizer(prompt, return_tensors="pt")
outputs = model.generate(**inputs, max_length=200)
print(tokenizer.decode(outputs[0]))
```

### ç”Ÿç”¢ç’°å¢ƒé…ç½®
```python
# production_config.py
MODEL_CONFIG = {
    "model_name": "openai/gpt-oss-120b",
    "device_map": "auto",
    "torch_dtype": torch.float16,
    "max_memory": {0: "80GB", 1: "80GB", 2: "80GB", 3: "80GB"},
    "load_in_4bit": True,
    "bnb_4bit_compute_dtype": torch.float16
}
```

## ğŸ”® æœªä¾†å±•æœ›èˆ‡è·¯ç·šåœ–

### å³å°‡æ¨å‡ºçš„åŠŸèƒ½
- **GPT-OSS 405B**ï¼šæ›´å¤§è¦æ¨¡çš„ 405B åƒæ•¸ç‰ˆæœ¬
- **å¤šæ¨¡æ…‹æ”¯æŒ**ï¼šåœ–åƒã€éŸ³é »ã€è¦–é »ç†è§£
- **å¯¦æ™‚å­¸ç¿’**ï¼šåœ¨ç·šå­¸ç¿’æ–°çŸ¥è­˜
- **è¯é‚¦å­¸ç¿’**ï¼šä¿è­·éš±ç§çš„åˆ†ä½ˆå¼è¨“ç·´

### ç¤¾å€ç™¼å±•è¨ˆåŠƒ
- **ä¸­æ–‡å„ªåŒ–ç‰ˆ**ï¼šå°ˆé–€é‡å°ä¸­æ–‡çš„å„ªåŒ–ç‰ˆæœ¬
- **å‚ç›´é ˜åŸŸæ¨¡å‹**ï¼šæ³•å¾‹ã€é†«ç™‚ã€é‡‘èç­‰å°ˆæ¥­ç‰ˆæœ¬
- **é‚Šç·£è¨­å‚™éƒ¨ç½²**ï¼šæ‰‹æ©Ÿã€IoT è¨­å‚™å„ªåŒ–
- **æ•™è‚²ç‰ˆ**ï¼šå°ˆé–€ç‚ºæ•™è‚²å ´æ™¯è¨­è¨ˆçš„è¼•é‡ç‰ˆ

### ç”Ÿæ…‹ç³»çµ±å»ºè¨­
- **å·¥å…·éˆå®Œå–„**ï¼šè¨“ç·´ã€å¾®èª¿ã€éƒ¨ç½²å·¥å…·
- **ç¤¾å€è²¢ç»**ï¼šé–‹æºç¤¾å€å…±åŒæ”¹é€²
- **æ¨™æº–åˆ¶å®š**ï¼šæ¨å‹•é–‹æº AI æ¨™æº–
- **æ•™è‚²æ¨å»£**ï¼šæ™®åŠ AI æŠ€è¡“æ•™è‚²

## ğŸ“ çµè«–

GPT-OSS 20B å’Œ 120B çš„ç™¼ä½ˆæ¨™èªŒè‘— AI æ°‘ä¸»åŒ–çš„é‡è¦é‡Œç¨‹ç¢‘ã€‚é€™ä¸åƒ…æ˜¯æŠ€è¡“çš„çªç ´ï¼Œæ›´æ˜¯é–‹æºç²¾ç¥çš„å‹åˆ©ã€‚å°æ–¼ä¸­æ–‡é–‹ç™¼è€…å’Œä¼æ¥­ä¾†èªªï¼Œé€™æä¾›äº†å‰æ‰€æœªæœ‰çš„æ©Ÿæœƒä¾†æ§‹å»ºæœ¬åœŸåŒ–çš„ AI æ‡‰ç”¨ã€‚

ç„¡è«–ä½ æ˜¯ç ”ç©¶äººå“¡ã€é–‹ç™¼è€…é‚„æ˜¯ä¼æ¥­æ±ºç­–è€…ï¼Œç¾åœ¨éƒ½æ˜¯æ¢ç´¢ GPT-OSS çš„æœ€ä½³æ™‚æ©Ÿã€‚éš¨è‘—ç¤¾å€çš„å…±åŒåŠªåŠ›ï¼Œæˆ‘å€‘æœŸå¾…çœ‹åˆ°æ›´å¤šå‰µæ–°çš„ä¸­æ–‡ AI æ‡‰ç”¨èª•ç”Ÿã€‚

---

**ç«‹å³è¡Œå‹•**ï¼šè¨ªå• [Hugging Face](https://huggingface.co/openai) ä¸‹è¼‰æ¨¡å‹ï¼ŒåŠ å…¥ [GitHub ç¤¾å€](https://github.com/openai/gpt-oss) è²¢ç»ä»£ç¢¼ï¼Œæˆ–é—œæ³¨æˆ‘å€‘çš„åšå®¢ç²å–æœ€æ–°æŠ€è¡“åˆ†äº«ã€‚

*é€™ç¯‡æ–‡ç« æ˜¯å¦å°ä½ æœ‰å¹«åŠ©ï¼Ÿåœ¨è©•è«–å€åˆ†äº«ä½ çš„ GPT-OSS ä½¿ç”¨é«”é©—ï¼Œæˆ–è€…æå‡ºä½ é‡åˆ°çš„æŠ€è¡“å•é¡Œï¼*